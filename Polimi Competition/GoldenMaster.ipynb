{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"929e3097-7f23-4725-856d-ee86c83c68f4\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"929e3097-7f23-4725-856d-ee86c83c68f4\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"929e3097-7f23-4725-856d-ee86c83c68f4\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '929e3097-7f23-4725-856d-ee86c83c68f4' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"929e3097-7f23-4725-856d-ee86c83c68f4\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"929e3097-7f23-4725-856d-ee86c83c68f4\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"929e3097-7f23-4725-856d-ee86c83c68f4\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '929e3097-7f23-4725-856d-ee86c83c68f4' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"929e3097-7f23-4725-856d-ee86c83c68f4\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataframe management\n",
    "import pandas as pd             \n",
    "\n",
    "# numerical computation\n",
    "import numpy as np\n",
    "\n",
    "# visualization library\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "sns.set_context(rc={\"font.family\":'sans',\"font.size\":24,\"axes.titlesize\":24,\"axes.labelsize\":24})   \n",
    "\n",
    "\n",
    "# import matplotlib and allow it to plot inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# seaborn can generate several warnings, we ignore them\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "output_notebook()\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet, Lasso, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDate(x):\n",
    "    parts = [int(el) for el in x.split(\"/\")]\n",
    "    return date(parts[2], parts[1], parts[0])\n",
    "\n",
    "def r2_cv(model, sales_train, y, random_state=12345678):\n",
    "    r2= cross_val_score(model, sales_train, y, scoring=\"r2\", cv =KFold(10, shuffle=True, random_state=random_state)) \n",
    "    return(r2)\n",
    "\n",
    "def rmse_cv(model, sales_train, y, random_state=12345678):\n",
    "    rmse= np.sqrt(-cross_val_score(model, sales_train, y, scoring=\"neg_mean_squared_error\", cv =KFold(10, shuffle=True, random_state=random_state)))\n",
    "    return(rmse)\n",
    "\n",
    "def RegionError(region, data):\n",
    "    d = data[data[region] == 1][[\"StoreID\",\"NumberOfActualSales\",\"NumberOfSales\"]].groupby([\"StoreID\"]).agg(\"sum\")\n",
    "    res = abs(d[\"NumberOfActualSales\"]-d[\"NumberOfSales\"]).agg(\"sum\")\n",
    "    return res / d[\"NumberOfActualSales\"].agg(\"sum\")\n",
    "\n",
    "def q(col, quant, f):\n",
    "    t = sales[col].quantile(quant)\n",
    "    print(f'col {col} at {quant}-th quantile => {t}')\n",
    "    sales.loc[f(sales[col], t), col] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the notebook\n",
    "sales = sales_string_date=pd.read_csv('train.csv')\n",
    "\n",
    "#Removing tuples where stores are closed\n",
    "sales = sales[sales['IsOpen'] == 1]\n",
    "\n",
    "#converting to string columns that are labels\n",
    "for el in [\"StoreID\", \"Region\"]:\n",
    "    sales[el] = sales[el].apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unknown_per_columns = sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Max_Gust_SpeedKm_h has 409947 missing values. We decided not to impute it.\n",
    "Let's start with imputation of \"Events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsOpen</th>\n",
       "      <th>HasPromotions</th>\n",
       "      <th>NearestCompetitor</th>\n",
       "      <th>NumberOfCustomers</th>\n",
       "      <th>NumberOfSales</th>\n",
       "      <th>Region_AreaKM2</th>\n",
       "      <th>Region_GDP</th>\n",
       "      <th>Region_PopulationK</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_TemperatureC</th>\n",
       "      <th>Mean_VisibilityKm</th>\n",
       "      <th>Mean_Wind_SpeedKm_h</th>\n",
       "      <th>Min_Dew_PointC</th>\n",
       "      <th>Min_Humidity</th>\n",
       "      <th>Min_Sea_Level_PressurehPa</th>\n",
       "      <th>Min_TemperatureC</th>\n",
       "      <th>Min_VisibilitykM</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.0</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>80397.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>94779.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>94779.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "      <td>103661.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.459179</td>\n",
       "      <td>8601.390619</td>\n",
       "      <td>314.641910</td>\n",
       "      <td>4893.577276</td>\n",
       "      <td>11435.271770</td>\n",
       "      <td>13711.770926</td>\n",
       "      <td>3467.389500</td>\n",
       "      <td>4.989340</td>\n",
       "      <td>...</td>\n",
       "      <td>11.545769</td>\n",
       "      <td>15.176421</td>\n",
       "      <td>11.082558</td>\n",
       "      <td>3.092774</td>\n",
       "      <td>40.196747</td>\n",
       "      <td>1015.171096</td>\n",
       "      <td>6.551538</td>\n",
       "      <td>10.586121</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>134.812292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>12222.596970</td>\n",
       "      <td>159.283348</td>\n",
       "      <td>2238.517426</td>\n",
       "      <td>8284.862826</td>\n",
       "      <td>2736.202628</td>\n",
       "      <td>2694.401824</td>\n",
       "      <td>2.233223</td>\n",
       "      <td>...</td>\n",
       "      <td>7.492758</td>\n",
       "      <td>6.648346</td>\n",
       "      <td>5.112519</td>\n",
       "      <td>6.093297</td>\n",
       "      <td>18.033663</td>\n",
       "      <td>7.151478</td>\n",
       "      <td>6.591203</td>\n",
       "      <td>6.138289</td>\n",
       "      <td>0.087722</td>\n",
       "      <td>103.812782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>9893.000000</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1116.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>3375.000000</td>\n",
       "      <td>7215.000000</td>\n",
       "      <td>11849.000000</td>\n",
       "      <td>1293.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1011.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3614.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>4461.000000</td>\n",
       "      <td>9337.000000</td>\n",
       "      <td>13155.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10593.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>5918.000000</td>\n",
       "      <td>15566.000000</td>\n",
       "      <td>15931.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85070.000000</td>\n",
       "      <td>2206.000000</td>\n",
       "      <td>26641.000000</td>\n",
       "      <td>32221.000000</td>\n",
       "      <td>23931.000000</td>\n",
       "      <td>8146.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1038.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           IsHoliday    IsOpen  HasPromotions  NearestCompetitor  \\\n",
       "count  103661.000000  103661.0  103661.000000      103661.000000   \n",
       "mean        0.001042       1.0       0.459179        8601.390619   \n",
       "std         0.032261       0.0       0.498333       12222.596970   \n",
       "min         0.000000       1.0       0.000000          47.000000   \n",
       "25%         0.000000       1.0       0.000000        1116.000000   \n",
       "50%         0.000000       1.0       0.000000        3614.000000   \n",
       "75%         0.000000       1.0       1.000000       10593.000000   \n",
       "max         1.000000       1.0       1.000000       85070.000000   \n",
       "\n",
       "       NumberOfCustomers  NumberOfSales  Region_AreaKM2     Region_GDP  \\\n",
       "count      103661.000000  103661.000000   103661.000000  103661.000000   \n",
       "mean          314.641910    4893.577276    11435.271770   13711.770926   \n",
       "std           159.283348    2238.517426     8284.862826    2736.202628   \n",
       "min             0.000000       0.000000      344.000000    9893.000000   \n",
       "25%           215.000000    3375.000000     7215.000000   11849.000000   \n",
       "50%           280.000000    4461.000000     9337.000000   13155.000000   \n",
       "75%           372.000000    5918.000000    15566.000000   15931.000000   \n",
       "max          2206.000000   26641.000000    32221.000000   23931.000000   \n",
       "\n",
       "       Region_PopulationK    CloudCover       ...        Mean_TemperatureC  \\\n",
       "count       103661.000000  80397.000000       ...            103661.000000   \n",
       "mean          3467.389500      4.989340       ...                11.545769   \n",
       "std           2694.401824      2.233223       ...                 7.492758   \n",
       "min            816.000000      0.000000       ...               -11.000000   \n",
       "25%           1293.000000      3.000000       ...                 6.000000   \n",
       "50%           1892.000000      5.000000       ...                12.000000   \n",
       "75%           5727.000000      7.000000       ...                18.000000   \n",
       "max           8146.000000      8.000000       ...                30.000000   \n",
       "\n",
       "       Mean_VisibilityKm  Mean_Wind_SpeedKm_h  Min_Dew_PointC   Min_Humidity  \\\n",
       "count       94779.000000        103661.000000   103661.000000  103661.000000   \n",
       "mean           15.176421            11.082558        3.092774      40.196747   \n",
       "std             6.648346             5.112519        6.093297      18.033663   \n",
       "min             2.000000             3.000000      -17.000000      10.000000   \n",
       "25%            10.000000             6.000000       -2.000000      25.000000   \n",
       "50%            13.000000            10.000000        3.000000      37.000000   \n",
       "75%            19.000000            13.000000        8.000000      52.000000   \n",
       "max            31.000000            34.000000       18.000000     100.000000   \n",
       "\n",
       "       Min_Sea_Level_PressurehPa  Min_TemperatureC  Min_VisibilitykM  \\\n",
       "count              103661.000000     103661.000000      94779.000000   \n",
       "mean                 1015.171096          6.551538         10.586121   \n",
       "std                     7.151478          6.591203          6.138289   \n",
       "min                   991.000000        -12.000000          0.000000   \n",
       "25%                  1011.000000          1.000000          8.000000   \n",
       "50%                  1015.000000          7.000000         10.000000   \n",
       "75%                  1020.000000         12.000000         10.000000   \n",
       "max                  1038.000000         23.000000         31.000000   \n",
       "\n",
       "       Precipitationmm  WindDirDegrees  \n",
       "count    103661.000000   103661.000000  \n",
       "mean          0.003920      134.812292  \n",
       "std           0.087722      103.812782  \n",
       "min           0.000000       -1.000000  \n",
       "25%           0.000000       46.000000  \n",
       "50%           0.000000      124.000000  \n",
       "75%           0.000000      216.000000  \n",
       "max           4.060000      360.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_Events = sales['Events'].isnull()\n",
    "event_missing = sales[null_Events]\n",
    "event_missing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rain                           171189\n",
       "Fog                             56323\n",
       "Fog-Rain                        41804\n",
       "Rain-Thunderstorm               18116\n",
       "Rain-Snow                       14576\n",
       "Snow                            12541\n",
       "Fog-Rain-Thunderstorm            6545\n",
       "Fog-Snow                         2469\n",
       "Fog-Rain-Snow                    2364\n",
       "Thunderstorm                     1298\n",
       "Rain-Hail                        1148\n",
       "Rain-Snow-Hail                    513\n",
       "Fog-Rain-Snow-Hail                231\n",
       "Rain-Snow-Hail-Thunderstorm       193\n",
       "Fog-Rain-Hail-Thunderstorm        178\n",
       "Fog-Snow-Hail                     169\n",
       "Fog-Rain-Hail                     168\n",
       "Fog-Thunderstorm                  157\n",
       "Snow-Hail                         134\n",
       "Rain-Snow-Thunderstorm            131\n",
       "Rain-Hail-Thunderstorm             50\n",
       "Name: Events, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Events'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this, we discovered that when Event is null the weather is good, from the fact that Precipitationmm mean is almost 0.\n",
    "Furthermore, all the labels of Events are related to bad weather, that means that when no precipitation occurs the label is null.\n",
    "We will impute Event by replacing the missing values with \"Not Specified\" (later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we impute \"CloudCover\", making a distinction when it misses along with Events and when it misses on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103661, 36), (103661, 36), (23264, 36))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_Events = sales['Events'].isnull()\n",
    "null_CloudCover = sales['CloudCover'].isnull()\n",
    "cloudcover_missing = sales[(null_Events)]\n",
    "null_Events = sales['Events'].isnull()\n",
    "event_missing = sales[null_Events]\n",
    "event_cc_missing = sales[null_CloudCover & null_Events]\n",
    "cloudcover_missing.shape, event_missing.shape, event_cc_missing.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 28k tuples where both \"Events\" and \"CloudCover\" are missing, that means that the weather should be good.\n",
    "for the remaining (41k-28k) (i.e. where \"Events\" is not null!) tuples we impute the CloudCoverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_notmissing_cc_missing = sales[null_CloudCover & ~null_Events]\n",
    "#computing mean where CloudCover is not null\n",
    "mean_CC = sales[\"CloudCover\"].mean()\n",
    "event_notmissing_cc_missing[\"CloudCover\"] = event_notmissing_cc_missing[\"CloudCover\"].fillna(mean_CC)\n",
    "sales = pd.concat([sales[~null_CloudCover | null_Events], event_notmissing_cc_missing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we impute the remaining rows with CloudCover missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_Events = sales['Events'].isnull()\n",
    "CloudyButNotEvent = sales[null_Events]\n",
    "#there are some tuples with no Events but with the attribute CloudCover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cloudCover = sales[sales['CloudCover'].isnull()]\n",
    "mean_cloudCover = sales[\"CloudCover\"].mean()\n",
    "null_cloudCover[\"CloudCover\"] = null_cloudCover[\"CloudCover\"].fillna(mean_cloudCover)\n",
    "\n",
    "sales = pd.concat([sales[~sales['CloudCover'].isnull()], null_cloudCover])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we impute min,max,mean_VisibilityKm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if are all the same rows where visibility data are missing => yes, they are\n",
    "sales[[\"Max_VisibilityKm\", \"Mean_VisibilityKm\", \"Min_VisibilitykM\"]].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_visibility = sales[sales['Max_VisibilityKm'].isnull()]\n",
    "mean_vis_max = sales[\"Max_VisibilityKm\"].mean()\n",
    "mean_vis_mean = sales[\"Mean_VisibilityKm\"].mean()\n",
    "mean_vis_min = sales[\"Min_VisibilitykM\"].mean()\n",
    "\n",
    "null_visibility[\"Max_VisibilityKm\"] = null_visibility[\"Max_VisibilityKm\"].fillna(mean_vis_max)\n",
    "null_visibility[\"Mean_VisibilityKm\"] = null_visibility[\"Mean_VisibilityKm\"].fillna(mean_vis_mean)\n",
    "null_visibility[\"Min_VisibilitykM\"] = null_visibility[\"Min_VisibilitykM\"].fillna(mean_vis_min)\n",
    "\n",
    "sales = pd.concat([sales[~sales['Max_VisibilityKm'].isnull()], null_visibility])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we impute \"Events\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=sales.replace(np.nan,'NotSpecified', regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales.quantile(.99).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q(\"NearestCompetitor\", .95, lambda x, y: x > y)\n",
    "q(\"Precipitationmm\", .99, lambda x, y: x > y)\n",
    "q(\"Max_Wind_SpeedKm_h\", .99, lambda x,y: x > y)\n",
    "q(\"Max_Wind_SpeedKm_h\", .01, lambda x,y: x < y)\n",
    "q(\"Max_TemperatureC\", .99, lambda x,y: x > y)\n",
    "q(\"Max_TemperatureC\", .01, lambda x,y: x < y)\n",
    "q(\"Min_TemperatureC\", .99, lambda x,y: x > y)\n",
    "q(\"Min_TemperatureC\", .01, lambda x,y: x < y)\n",
    "q(\"Mean_Dew_PointC\", .98, lambda x,y: x > y)\n",
    "q(\"Mean_Dew_PointC\", .05, lambda x,y: x < y)\n",
    "q(\"Mean_Dew_PointC\", .98, lambda x,y: x > y)\n",
    "q(\"Mean_Dew_PointC\", .05, lambda x,y: x < y)\n",
    "q(\"Mean_Humidity\", .95, lambda x,y: x > y)\n",
    "q(\"Mean_Humidity\", .01, lambda x,y: x < y)\n",
    "q(\"Min_VisibilitykM\", .98, lambda x,y: x > y)\n",
    "q(\"Min_Humidity\", .02, lambda x,y: x < y)\n",
    "q(\"Min_Humidity\", .98, lambda x,y: x > y)\n",
    "q(\"Mean_Wind_SpeedKm_h\", .99, lambda x,y: x > y)\n",
    "q(\"Mean_TemperatureC\", .01, lambda x,y: x < y)\n",
    "q(\"Mean_TemperatureC\", .99, lambda x,y: x > y)\n",
    "q(\"Mean_VisibilityKm\", .01, lambda x,y: x < y)\n",
    "q(\"Mean_VisibilityKm\", .99, lambda x,y: x > y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min_Sea_Level_PressurehPa  ->dropparla\n",
    "#WindDirDegrees             -> inutile secondo me -> o la si categorizza in nord sud est ovest e la si fa con One Hot Encoding\n",
    "#x=\"\"\n",
    "#sales[x].describe()\n",
    "#sales[x].quantile(.01)\n",
    "#sales[x].quantile(.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the numerical features\n",
    "numeric_feats = sales.dtypes[sales.dtypes != \"object\"].index\n",
    "# compute the skewness but only for non missing variables (we already imputed them but just in case ...)\n",
    "skewed_feats = sales[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "skewness = pd.DataFrame({\"Variable\":skewed_feats.index, \"Skewness\":skewed_feats.data})\n",
    "# select the variables with a skewness above a certain threshold\n",
    "skewness = skewness.sort_values('Skewness', ascending=[0])\n",
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=skewness['Variable'], y=skewness['Skewness'])\n",
    "plt.ylim(0,25)\n",
    "plt.xlabel('Numerical Variables', fontsize=15)\n",
    "plt.ylabel('Skewness', fontsize=15)\n",
    "plt.title('', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.drop(['IsHoliday','NumberOfCustomers', \"NumberOfSales\"])\n",
    "sales[skewed_feats.index] = np.log1p(sales[skewed_feats.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the correlation, we see that the following variables do not add any additional information. \n",
    "Max_Dew_PointC, Min_Dew_PointC, Max_Sea_Level_PressurehPa, Mean_Sea_Level_PressurehPa, Max_Gust_SpeedKm_h\n",
    "Finally, we drop 'NumberOfCustomers' because is not present in the submission dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=sales.drop(columns=['Max_Dew_PointC','Min_Dew_PointC','Max_Sea_Level_PressurehPa','Mean_Sea_Level_PressurehPa','Max_Gust_SpeedKm_h'])\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop of the row where IsOpen==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=sales[sales['IsOpen']==1]\n",
    "sales=sales.drop(columns=['IsOpen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Date to weekday label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"Date\"] = sales[\"Date\"].apply(toDate)\n",
    "sales[\"Day_Of_Week\"] = sales[\"Date\"].astype(\"datetime64\").dt.weekday_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummify variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.get_dummies(sales, columns=['StoreType','Events','AssortmentType', \"Region\", \"Day_Of_Week\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Definition\n",
    "Separating the last 2 months, and use those as a test set and comparing the total of the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train = date(2018, 1, 1)\n",
    "train = sales[sales[\"Date\"] - start_train < timedelta(0)]\n",
    "test = sales[sales[\"Date\"] - start_train > timedelta(days=1)]\n",
    "train = train.drop(columns=[\"Date\"])\n",
    "test = test.drop(columns=[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding of train and set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First try: MultipleLinear Regression for Region 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by predicting the number of customers for Region 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region_label = \"Region_3\"\n",
    "train_region3= train.loc[train[Region_label] == 1]\n",
    "test_region3= test.loc[test[Region_label] == 1] \n",
    "train_region3.shape , test_region3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 : PREDICT THE NUMBER OF CUSTOMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_region3_step1 = train_region3.drop(columns=['NumberOfSales','NumberOfCustomers'])\n",
    "test_x_region3_step1 = test_region3.drop(columns=['NumberOfSales','NumberOfCustomers'])\n",
    "\n",
    "train_y_region3_step1 = pd.DataFrame(data = train_region3['NumberOfCustomers'])\n",
    "test_y_region3_step1 = pd.DataFrame(data = test_region3['NumberOfCustomers']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = RandomForestRegressor()\n",
    "model_simple.fit(train_x_region3_step1, train_y_region3_step1)\n",
    "yp = model_simple.predict(test_x_region3_step1) #yp=predicted customers del test\n",
    "\n",
    "# compute R2 for train and using crossvalidation\n",
    "r2_simple_train = r2_score(test_y_region3_step1,yp)\n",
    "r2_xval_simple =  r2_cv(model_simple, test_x_region3_step1, test_y_region3_step1)\n",
    "\n",
    "# compute RMSE for train and using crossvalidation\n",
    "rmse_simple_train = mean_squared_error(test_y_region3_step1,yp,multioutput='raw_values')\n",
    "rmse_xval_simple =  rmse_cv(model_simple, test_x_region3_step1,test_y_region3_step1)\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "print(\"==================================================\")\n",
    "print(\"\\t                  Train R2=%.3f\"%(r2_simple_train))\n",
    "print(\"\\t10-fold Crossvalidation R2=%.3f\"%(r2_xval_simple.mean()))\n",
    "print(\"\\t                  Train RMSE=%.3f\"%(rmse_simple_train))\n",
    "print(\"\\t10-fold Crossvalidation RMSE=%.3f\"%(rmse_xval_simple.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(test_y_region3_step1)\n",
    "check[Region_label] = 1\n",
    "check[\"NumberOfActualSales\"] = test_y_region3_step1[[\"NumberOfCustomers\"]]\n",
    "check[\"NumberOfSales\"] = yp\n",
    "check[\"StoreID\"] = test_x_region3_step1[[\"StoreID\"]]\n",
    "RegionError(Region_label, check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 : PREDICT THE NUMBER OF SALES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train over all the regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_step2 = train.drop(columns=['NumberOfSales'])\n",
    "train_y_step2 = pd.DataFrame(data = train['NumberOfSales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test still over region 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_region3_step2 = test_region3.drop(columns=['NumberOfSales','NumberOfCustomers'])\n",
    "test_x_region3_step2['NumberOfCustomers']= yp\n",
    "test_y_region3_step2 = pd.DataFrame(data = test_region3['NumberOfSales']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only the most correlated features with the sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_step2 = train_x_step2[['NumberOfCustomers','Region_AreaKM2','HasPromotions','IsHoliday','Region_GDP',Region_label,\"StoreID\"]]\n",
    "test_x_region3_step2 = test_x_region3_step2[['NumberOfCustomers','Region_AreaKM2','HasPromotions','IsHoliday','Region_GDP', Region_label, \"StoreID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple_step2 = RandomForestRegressor()\n",
    "model_simple_step2.fit(train_x_step2, train_y_step2)\n",
    "yp2 = model_simple_step2.predict(test_x_region3_step2) #yp2= le sales predette alla fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute R2 for train and using crossvalidation\n",
    "r2_simple_train = r2_score(test_y_region3_step2,yp2)\n",
    "r2_xval_simple =  r2_cv(model_simple, test_x_region3_step2, test_y_region3_step2)\n",
    "\n",
    "# compute RMSE for train and using crossvalidation\n",
    "rmse_simple_train = mean_squared_error(test_y_region3_step2, yp2, multioutput='raw_values')\n",
    "rmse_xval_simple =  rmse_cv(model_simple, test_x_region3_step2, test_y_region3_step2)\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "print(\"==================================================\")\n",
    "print(\"\\t                  Train R2=%.3f\"%(r2_simple_train))\n",
    "print(\"\\t10-fold Crossvalidation R2=%.3f\"%(r2_xval_simple.mean()))\n",
    "print(\"\\t                  Train RMSE=%.3f\"%(rmse_simple_train))\n",
    "print(\"\\t10-fold Crossvalidation RMSE=%.3f\"%(rmse_xval_simple.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(test_y_region3_step2)\n",
    "check[Region_label] = 1\n",
    "check[\"NumberOfActualSales\"] = test_y_region3_step2[[\"NumberOfSales\"]]\n",
    "check[\"NumberOfSales\"] = yp2\n",
    "check[\"StoreID\"] = test_x_region3_step2[[\"StoreID\"]]\n",
    "RegionError(Region_label, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
